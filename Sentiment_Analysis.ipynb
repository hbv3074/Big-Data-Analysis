{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "4F55fQtUWLM-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "uQ51RMCHWaau"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df_train = spark.read.csv(\"/content/twitter_training.csv\", header=False, inferSchema=True)\n",
        "df_train = df_train.toDF(\"ID\", \"Topic\", \"Sentiment\", \"Tweet\")\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):  # Ensure text is a string\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    return text\n",
        "\n",
        "clean_text_udf = udf(clean_text, StringType())\n",
        "df_train = df_train.withColumn(\"Cleaned_Tweet\", clean_text_udf(col(\"Tweet\")))\n",
        "\n",
        "# Convert labels to numerical format\n",
        "indexer = StringIndexer(inputCol=\"Sentiment\", outputCol=\"label\")\n",
        "\n",
        "# Tokenization and TF-IDF feature extraction\n",
        "tokenizer = Tokenizer(inputCol=\"Cleaned_Tweet\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "\n",
        "# Naive Bayes classifier\n",
        "nb = NaiveBayes()\n",
        "\n",
        "# Build pipeline\n",
        "pipeline = Pipeline(stages=[indexer, tokenizer, remover, hashingTF, idf, nb])\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = df_train.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train the model\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluation\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "predictions.select(\"Sentiment\", \"Cleaned_Tweet\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c5ZZQZHWuUm",
        "outputId": "11e5a62f-a864-4e86-f0dd-badc0ae5d6a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.66\n",
            "+----------+--------------------+----------+\n",
            "| Sentiment|       Cleaned_Tweet|prediction|\n",
            "+----------+--------------------+----------+\n",
            "|  Negative|          amazon wtf|       0.0|\n",
            "|  Negative|i am really disap...|       0.0|\n",
            "|  Negative|im really disappo...|       0.0|\n",
            "|   Neutral|admit it subs cra...|       2.0|\n",
            "|  Negative| amazon probably ...|       0.0|\n",
            "|  Negative|amazon probably s...|       0.0|\n",
            "|Irrelevant|youve purchased  ...|       0.0|\n",
            "|   Neutral|love speculative ...|       3.0|\n",
            "|  Negative|amazon be having ...|       0.0|\n",
            "|  Negative|amazon be having ...|       2.0|\n",
            "+----------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get label encoding mapping\n",
        "labels_map = model.stages[0].labels\n",
        "print(\"Label Encoding Mapping:\")\n",
        "for i, label in enumerate(labels_map):\n",
        "    print(f\"{label} -> {i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXDyU4gWXDie",
        "outputId": "ef67fee7-65c7-40cf-9909-433aff64e3c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoding Mapping:\n",
            "Negative -> 0\n",
            "Positive -> 1\n",
            "Neutral -> 2\n",
            "Irrelevant -> 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.rdd.getNumPartitions())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf5AA0f3k9jH",
        "outputId": "fbb3c803-b80e-4618-bd0b-2ce640d94a93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    }
  ]
}